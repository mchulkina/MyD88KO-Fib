---
title: "MyD88-FO - Bacterial Microbiome 16S Analysis"
author: "Hanh Tran - Davenport Lab"
date: "`r Sys.Date()`"
output: 
  rmdformats::html_clean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## I. Overview

This document contains the microbiota analysis, visualization, and intepretation of microbial community composition and diversity between two groups of mice (control and MYD88-FO knockout). We want to assess if there is any difference between bacterial communities between the experimental group of mice and the control group.

## II. Objectives

-   Explore the datasets and check data properties (sparsity and sequencing depth).

-   Define, calculate, and interpret alpha- and beta-diversity of microbial communities.

-   Filter the data and normalize data by sample.

-   Visualize and interpret microbial community composition for different treatments.

-   Perform statistical tests to test the differences among treatments.

## III. Analysis (Part 1: Dada preprocessing: From FASTQ to ASV)

### 1. Trim adapter and primers using cutadapt

In the Bash terminal, change directory to 01/Analysis folder and run cutadapt to remove adapter sequences in the reads.

```{bash, eval=FALSE}
cd ./01_Analysis/
mkdir ./01_Cutadapt

# extract the file name in the file directories and store
ls ./00_RawData/*_1.fastq.gz | xargs -n1 basename | cut -f1 -d "_" > fileNames.txt

cutadapt --version # 4.6

# iterate cutadapt through all fastq files in the directory 
for sample in $(cat fileNames.txt)
do
  echo "On sample: $sample"
  if [ ! -d "./01_Cutadapt" ]; then
    mkdir "./01_Cutadapt"
  fi
  
  cutadapt --adapter CCTAYGGGRBGCASCAG...GGACTACNNGGGTATCTAAT \
            --minimum-length 215 --discard-untrimmed \
            -o ./01_Cutadapt/${sample}"_1_cutadapt.fastq.gz" -p ./01_Cutadapt/${sample}"_2_cutadapt.fastq.gz" -Z \
            ./00_RawData/${sample}"_1.fastq.gz" ./00_RawData/${sample}"_2.fastq.gz" \
            >> ./01_Cutadapt/cutadapt_primer_trimming_stats.txt 2>&1
done
      
```

Look through the cutadapt_primer_trimming_stats.txt file to get an idea of how things were trimmed.

```{bash, eval=FALSE}
paste fileNames.txt <(grep "Total basepairs processed:" ./01_Cutadapt/cutadapt_primer_trimming_stats.txt | cut -f3 -d "(" | tr -d ")") <(grep "Total written (filtered)" ./01_Cutadapt/cutadapt_primer_trimming_stats.txt | cut -f3 -d "(" | tr -d ")")
```

#### Install and load the required packages

```{R, eval=TRUE}
library("knitr")
library('phyloseq')
library('dada2')
library("dendextend")
library("DESeq2")
library("ggplot2")
library("MicrobiotaProcess")
library("ggtree")
library("DECIPHER")
library("phangorn")

```

#### Define path variables

Read the names of FASTQ files and perform some string manipulation to get a file list of the forward and reverse files

```{R, eval = FALSE}
# Set the path
path <- "./MYD88"
files.path <- "./"
```

```{R, eval=TRUE}
# Scan the file that contains all the fastq files names
sample_files <- scan("01_Analysis/fileNames.txt", what = "character")
head(sample_files)

# Use indices to get the actual file names
forward_reads <- file.path("01_Analysis","01_Cutadapt", paste0(sample_files,"_1_cutadapt.fastq.gz"))
reverse_reads <- file.path("01_Analysis","01_Cutadapt", paste0(sample_files,"_2_cutadapt.fastq.gz"))
                           
head(forward_reads) # Check the variables and make sure the file names look correct
head(reverse_reads)

```

### 2. Filter and Trim

Begin by filtering out the reads, with low sequencing quality and trimming reads to a consistent length.

Create the variables to store output file names of reads being filtered in the next step. This is essential so that we have consistent naming system throughout the analysis.

```{r, eval=TRUE}
# Create a sub-directory under home directory to store filtered files
filtered_path <- file.path("01_Analysis","02_Dada2_Filtered")
if (!file_test("-d", filtered_path)) dir.create(filtered_path) # this code is to check whether the "filtered_path" already exists. If it doesn't exist, then 'dir.create' function is used to create the "filtered_path" directory.

# Make variables to hold filtered reads from forward and reverse files, respectively

filtered_forward_reads <- file.path("01_Analysis", "02_Dada2_Filtered", paste0(sample_files, "_1_filtered_cutadapt.fastq.gz"))
filtered_reverse_reads <- file.path("01_Analysis", "02_Dada2_Filtered", paste0(sample_files, "_2_filtered_cutadapt.fastq.gz"))

head(filtered_forward_reads)
head(filtered_reverse_reads) # Check the variables and make sure the file names look correct

```

Inspect the read quality profiles

```{r, eval=TRUE}
# Assess the read quality by plotting forward and reverse reads
plotQualityProfile(forward_reads[1:2])
plotQualityProfile(reverse_reads[1:2])

```

Now, as shown in the quality plots, both forward and reverse reads seem to maintain good quality throughout. Therefore, we choose to truncate the forward reads at 250, and the reverse reads at 250. We also choose to trim the first 10 nucleotides of each read based on the FASTQC plot showing the first 10 bases that have low quality mostly due to technical sequencing errors. We combine these trimming parameters with standard filtering parameters. the most important being the enforcement of a maximum of 2 expected errors per-read. Trimming and filtering is performed on paired reads jointly. Hence, both reads must pass the filter for the pair to pass. From steps above, after cutting off primers, we're expecting a typical amplicon size of V3-V4 primers to be around 220bps, so set the trunclen parameter accordingly.

```{r, eval=TRUE}
out <- filterAndTrim(forward_reads,filtered_forward_reads,reverse_reads,filtered_reverse_reads, truncLen=c(220,0),
                      maxN=0, maxEE=2, truncQ=2, rm.phix=TRUE, 
                     compress = TRUE, multithread = TRUE)
saveRDS(out, "./RDS/filterAndTrim_out.rds")
```

Next, we plot the reads to determine their quality post trimming. Here, we only plot the first two files and see if the overall quality improves.

```{r, eval=TRUE}
# Assess the read quality by plotting forward and reverse reads
plotQualityProfile(filtered_forward_reads[1:2])
plotQualityProfile(filtered_reverse_reads[1:2])
```

### Denoise

Generate error model

```{r, eval=TRUE}
err_forward_reads <- learnErrors(filtered_forward_reads)
saveRDS(err_forward_reads, "./RDS/err_forward_reads.RDS")

err_reverse_reads <- learnErrors(filtered_reverse_reads)
saveRDS(err_reverse_reads, "./RDS/err_reverse_reads.RDS")

# plot the error models
plotErrors(err_forward_reads, nominalQ=TRUE)
plotErrors(err_reverse_reads, nominalQ=TRUE)
```

The red line is what is expected based on the black line represents the estimate, and the black dots represent the observed. Generally speaking, we want the observed (black dots) to track well with the estimated (black line).

Denoising or dereplication is a common step in many amplicon processing workflows. Instead of keeping 100 identical sequences and doing all downstream processing to all 100, we can just keep/process one of them, and just attach the number 100 to it. When DADA2 dereplicates sequences, it also generates a new quality-score profile for each unique sequence based on the average quality score of each base of all of the sequences that were replicates of it.

```{r, eval=TRUE}
derep_forward <- derepFastq(filtered_forward_reads, verbose=TRUE)
saveRDS(derep_forward,"./RDS/derep_forward.RDS")

derep_reverse <- derepFastq(filtered_reverse_reads, verbose=TRUE)
saveRDS(derep_reverse,"./RDS/derep_reverse.RDS")

```

### 3. Sample inference

Here is the main purpose of DADA2, that is to infer true biological sequences based on amplicon given. It does it by incorporating the consensus quality profiles and abundances of each uniq sequence, and then figuring out if each sequence is more likely to be of biological origin or more likely to be spurious.

```{r, eval=TRUE}
dada_forward <- dada(derep_forward, err=err_forward_reads, multithread = T)
saveRDS(dada_forward,"./RDS/dada_forward.RDS")

dada_reverse <- dada(derep_reverse, err=err_reverse_reads, multithread = T)
saveRDS(dada_reverse,"./RDS/dada_reverse.RDS")

```

#### Merge forward and reverse reads

Now DADA2 merges the forward and reverse amplicon sequence variants (ASVs) to reconstruct our full target amplicon requiring the overlapping region to be identical between the two sequences. By default, it requires at least 12bps overlap.

```{r, eval=TRUE}
merged_amplicons <- mergePairs(dada_forward, derep_forward, dada_reverse, derep_reverse, trimOverhang = TRUE)
saveRDS(merged_amplicons,"./RDS/merged_amplicons.RDS")
```

#### Generate count table

This is one of the main outputs from processing an amplicon dataset, this table is required for assigning taxonomy in later step.

```{r, eval=TRUE}
seq_table <- makeSequenceTable(merged_amplicons)
class(seq_table)
dim(seq_table)
```

#### Chimera identification

DADA2 identifies likely chimeras by aligning each sequence with those that were recovered in greater abundance (high counts) and then see if there are any lower abundance sequences that can be made exactly by mixing left and right portions of two of the more-abundance ones. Then, these are identified as chimera and removed.

```{r, eval=TRUE}
seq_table_nochim <- removeBimeraDenovo(seq_table, verbose=T)
saveRDS(seq_table_nochim,"./RDS/seq_table_nochim.RDS")

# Calculate the portion of chimera in the sequence table
sum(seq_table_nochim)/sum(seq_table)
```

#### Generate a table tracking reads throughout the pipeline

This part is to generate a table showing how many reads were removed at various points throughout the pipeline. If we are left with too few sequences at the end, this can help pointing towards where we should start digging into the point where they were dropped and adjust the parameters accordingly.

```{r, eval=TRUE}
## Make a function:
getN <- function(x) sum(getUniques(x))

## Make a table
summary_table <- data.frame(row.names=sample_files, dada2_input=out[,1], filtered=out[,2], dada_foward=sapply(dada_forward, getN),
                            dada_reverse=sapply(dada_reverse, getN), nochim=rowSums(seq_table_nochim), 
                            final_perc_reads_retained=round(rowSums(seq_table_nochim)/out[,1]*100,1))
summary_table
```

It might be useful to save it as a regular file in the current directory.

```{r, eval=TRUE}
write.table(summary_table, "read_count_tracking.tsv", quote=FALSE, sep="\t", col.names=NA)
```

### 4. Assigning taxonomic classification

In this part, we will assign taxonomy to ASVs. The DADA2 package provides a native implementation of the naive Bayesian classifier method for this purpose. The 'assignTaxonomy' function takes input as a set of sequences to be classified and a training set of reference sequences with known taxonomy. In this analysis, we will use the reference dataset 'silva_nr_v132_train_set.fa.gz'

```{r, eval=TRUE}
tax_DADA2 <- assignTaxonomy(seq_table_nochim, "./01_Analysis/silva_nr_v123_train_set.fa.gz") ## This step can take a while depending on your computing resources and dataset size.

# save the output taxonomy object
saveRDS(tax_DADA2, "./01_Analysis/taxonomy.RDS")
tax_DADA2 <- readRDS("./RDS/taxonomy.RDS")
```

### 5. Extracting results from DADA2

The standard outputs from amplicon processing are: A fasta file, a count table (ASV table), and a taxonomy table. So here is one way we can generate those files from outputs of DADA2.

```{r, eval=TRUE}
# Load the metadata table
sample_info_tab <- read.table("./01_Analysis/MYD88_metadata.txt", header=T, row.names=1,
                   check.names=F, sep="\t")

## giving our seq headers more manageable names (DADA2_ASV_1, DADA2_ASV_2, DADA2_ASV_3, etc.)
seq_table_nochim <- readRDS("./RDS/seq_table_nochim.RDS")
asv_seqs_DADA2 <- colnames(seq_table_nochim)
asv_headers_DADA2 <- vector(dim(seq_table_nochim)[2], mode="character")

for (i in 1:dim(seq_table_nochim)[2]) {
  asv_headers_DADA2[i] <- paste(">DADA2_ASV", i, sep="_")
}

## making and writing out a fasta of our final ASV seqs:
asv_fasta_DADA2 <- c(rbind(asv_headers_DADA2, asv_seqs_DADA2))
write(asv_fasta_DADA2, "./01_Analysis/03_Dada2_results/DADA2_ASVs.fa")

## count table"
asv_table_DADA2 <- t(seq_table_nochim)
row.names(asv_table_DADA2) <- sub(">", "", asv_headers_DADA2)
colnames(asv_table_DADA2) <- sub("\\.raw_1_filtered_cutadapt\\.fastq\\.gz$", "", colnames(asv_table_DADA2))
write.table(asv_table_DADA2, "./01_Analysis/03_Dada2_results/DADA2_ASVs_counts.tsv", sep="\t", quote=F, col.names=NA)


## taxonomy table
asv_tax_DADA2 <- readRDS("./RDS/taxonomy.RDS")
taxa.print <- asv_tax_DADA2 # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
rownames(asv_tax_DADA2) <- gsub(pattern=">", replacement="", x=asv_headers_DADA2) # replace the taxa headers with simplified name (DADA2_ASV_1,...)
write.table(asv_tax_DADA2, "./01_Analysis/03_Dada2_results/DADA2_taxonomy.tsv", sep="\t", quote=F, col.names=NA)

```

### 6. Construct phylogenetic tree

Phylogenetic relatedness is commonly used to inform downstream analyses, especially the calculation of phylogeny-aware distances (unifrac) between microbial community. The DADA2 sequence inference method is reference-free, so we must construct the phylogenetic tree relating the inferred sequence variants de novo, meaning no reference. We begin by performing a multiple alignment using the DECIPHER R package (Wright 2015).

```{r, eval=TRUE}
# Get the sequences from seq table
seqs <- getSequences(seq_table_nochim)
names(seqs) <- seqs # This propagates to the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA,verbose=FALSE)
```

The phangorn package is used to construct a phylogenetic tree. Here, we first construct a neighbor-joining tree, then fit a GTR+G+I (Generalized time-reversible with Gamma rate variation) maximum likelihood tree using the neighbor-joining tree as a starting point.

```{r, eval=TRUE}
phangAlign <- phyDat(as(alignment, "matrix"), type="DNA")
saveRDS(phangAlign,"./RDS/phangAlign.RDS")

dm <- dist.ml(phangAlign)
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phangAlign)
saveRDS(fit, "./RDS/fit.RDS")
fit <- readRDS("./RDS/fit.RDS")
```

```{r, eval=TRUE}
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
        rearrangement = "NNI", control = pml.control(trace = 0))

saveRDS(fitGTR, './RDS/fitGTR.RDS')

write.tree(fitGTR$tree, file = "GTR.phy")
```

### 7. Combine data into phyloseq object

```{r, eval=TRUE}
## Create the phyloseq object:
count_tab_phy <- otu_table(asv_table_DADA2, taxa_are_rows=T)
tax_tab_phy <- phyloseq::tax_table(asv_tax_DADA2)

sample_info_tab <- read.table("./01_Analysis/MYD88_metadata.txt", header=T, row.names=1,
                   check.names=F, sep="\t")
sample_info_tab_phy <- sample_data(sample_info_tab)

phylogenetic_tree <- phyloseq::phy_tree(fitGTR$tree)

phylogenetic_tree$tip.label <- taxa_names(count_tab_phy)

ASV_physeq <- phyloseq(count_tab_phy, tax_tab_phy, sample_info_tab_phy, phylogenetic_tree)

saveRDS(ASV_physeq,"./RDS/ASV_physeq.RDS")
```

## III. Analysis (Part 2: Data exploration and properties)

### 1. Data summary and assessment.

While there are numerous possible ways to evaluate your data, a standard starting approach would consist of the following steps:

-   Evaluate Amplicon Sequence Variants (ASV) summary statistics

-   Detect and remove outlier samples

-   Taxon cleaning - remove Mitochondria and Chloroplast

-   Prevalence estimation and filtering

Load all required libraries

```{r, eval=TRUE}
library("knitr")
library('phyloseq')
library('dada2')
library("dendextend") # load the package
library("DESeq2")
library("ggplot2")
library("MicrobiotaProcess")
library("ggtree")
library("vegan")
library("phangorn")
library("DECIPHER")
library("plyr"); packageVersion("plyr")
library("tidyverse"); packageVersion("tidyverse")
library("phyloseq"); packageVersion("phyloseq")
library("vegan"); packageVersion("vegan")
library("gridExtra"); packageVersion("gridExtra")
library("knitr"); packageVersion("knitr")
library("DESeq2"); packageVersion("DESeq2")
library("plotly"); packageVersion("plotly")
library("microbiome"); packageVersion("microbiome")
library("ggpubr"); packageVersion("ggpubr")
library("data.table"); packageVersion("data.table")
library("ALDEx2")
library("RColorBrewer")
library("ANCOMBC")
library('gghalves')
library('ggalluvial')
library('ggtreeExtra')
library('microbiomeMarker')
library('ggh4x')
library('scales')
library('reshape2') # Flexibly Reshape Data: A Reboot of the Reshape Package.
library('ggnewscale') # Multiple Fill and Colour Scales in 'ggplot2'.
library('patchwork')
```

#### a. Evaluate ASVs

Begin by running the following R chunk to produce ASV summary plots.

```{r, eval = FALSE}
# Load the phyloseq object.
ps0 <- readRDS("./RDS/ASV_physeq.RDS")

# Create a new data frame of the sorted row sums, a column of sorted values from 1 to the total number of individuals/counts for each ASV and a categorical variable stating these are all ASVs.
readsumsdf <- data.frame(nreads = sort(taxa_sums(ps0), decreasing = TRUE),
                        sorted = 1:ntaxa(ps0),
                        type = "ASVs")

# Make a data frame with a column for the read counts of each sample for histogram production
sample_sum_df <- data.frame(sum = sample_sums(ps0))

```

Generate a bar plot with number of reads on y-axis for each taxa, sorted from most to least abundant.

```{r, eval=TRUE}
p.reads = ggplot(readsumsdf, aes(x = sorted, y = nreads)) +
  geom_bar(stat = "identity") +
  ggtitle("ASV Assessment") +
  scale_y_log10() +
  facet_wrap(~type, scales = "free") +
  ylab("# of Sequences")

# Histogram of the number of Samples (y-axis) at various read depths
p.reads.hist <- ggplot(sample_sum_df, aes(x = sum)) + 
  geom_histogram(color = "black", fill = "firebrick3", binwidth = 150) +
  ggtitle("Distribution of sample sequencing depth") + 
  xlab("Read counts") +
  ylab("# of Samples")

# Final plot, side-by-side
grid.arrange(p.reads, p.reads.hist, ncol = 2)

# Basic summary statistics
summary(sample_sums(ps0))

```

The above data assessment is useful for getting an idea of 1) the number of sequences per taxa (left plot). This will normally be a "long tail" with some taxa being highly abundant in the data tapering off to taxa with very few reads, 2) the number of reads per sample. Note the spike at the lowest number of reads due to samples taken from mice given antibiotics. Very low read count can be indicative of a failed reaction. Both of these plots will help give an understanding of how your data are structured across taxa and samples and will vary depending on the nature of the samples.

Importantly, at each stage you should document and justify your decisions. If you are concerned that sample removal will alter the interpretation of your results, you should run your analysis on the full data and the data with the sample(s) removed to see how the decision affects your interpretation.

#### b. Detect and remove outliers

Detecting and potentially removing samples outliers (those samples with underlying data that do not conform to experimental or biological expectations) can be useful for minimizing technical variance. One way to identify sample outliers is shown in the R chunk below.

```{r sample-removal-identification, eval=TRUE}
# Format a data table to combine sample summary data with sample variable data
ss <- sample_sums(ps0)
sd <- as.data.frame(sample_data(ps0))
ss.df <- merge(sd, data.frame("ASV" = ss), by ="row.names")


# Plot the data by the treatment variable
y = 1000 # Set a threshold for the minimum number of acceptable reads. Can start as a guess
x = "Isolation.Source" # Set the x-axis variable you want to examine
label = "Sample_name" # This is the label you want to overlay on the points

p.ss.boxplot <- ggplot(ss.df, aes_string(x, y = "ASV", color = "Treatment")) + 
  geom_boxplot(outlier.colour="NA", position = position_dodge(width = 0.8)) +
  geom_jitter(size = 2, alpha = 0.6) +
  scale_y_log10() +
  facet_wrap(~Treatment) +
  geom_hline(yintercept = y, lty = 2) +
  geom_text(aes_string(label = label), size = 3, nudge_y = 0.05, nudge_x = 0.05)
p.ss.boxplot

```

The data does not have samples with fewer than 1,000 ASV in the treatment groups. So we don't need to remove any outlier sample.

#### c. Taxon cleaning

This part is to removs taxa not-typically part of a bacterial microbiome analysis such as Mitochondria and Chloroplast.

```{r taxon-cleaning, eval=TRUE}
# Some examples of taxa you may not want to include in your analysis
get_taxa_unique(ps0, "Kingdom")
get_taxa_unique(ps0, "Class")

ps0 # Check the number of taxa prior to removal
ps1 <- ps0 %>%
  subset_taxa(
    Kingdom == "Bacteria" &
    Family  != "Mitochondria" &
    Class   != "Chloroplast" &
    Phylum != "Cyanobacteria/Chloroplast"
  )
ps1 # Confirm that the taxa were removed
get_taxa_unique(ps1, "Kingdom")
get_taxa_unique(ps1, "Class")

rank_names(ps0)
# Create table, number of features for each phyla
table(phyloseq::tax_table(ps1)[, "Phylum"], exclude = NULL)
```

#### d. Prevalance assessment

Identification of taxa that are poorly represented in an unsupervised manner can identify taxa that will have little to no effect on downstream analysis. Sufficient removal of these "low prevalence" features can enhance many analysis by focusing statistical testing on taxa common throughout the data. This approach is usually documented in methods sections of manuscripts, but will typically read something like, "Taxa present in fewer than 3% of all of the samples within the study population and less than 5% relative abundance were removed from all subsequent analysis. While the ultimate selection criteria can still be subjective, the following plots can be useful for making our selection criteria.

```{r prevalence-assessment, eval=TRUE}
# Prevalence estimation
# Calculate feature prevalence across the data set
prevdf <- apply(X = otu_table(ps1),MARGIN = ifelse(taxa_are_rows(ps1), yes = 1, no = 2),FUN = function(x){sum(x > 0)})

# Add taxonomy and total read counts to prevdf
prevdf <- data.frame(Prevalence = prevdf, TotalAbundance = taxa_sums(ps1), phyloseq::tax_table(ps1))

plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})

#Prevalence plot
prevdf1 <- subset(prevdf, Phylum %in% get_taxa_unique(ps0, "Phylum"))
p.prevdf1 <- ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(ps1),color=Family)) +
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) +
  geom_point(size = 3, alpha = 0.7) +
  scale_x_log10() +
  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) +
  theme(legend.position="none") +
  ggtitle("Phylum Prevalence in All Samples\nColored by Family")
p.prevdf1

```

A useful next step is to explore feature prevalence in the dataset, which we will define here as the number of samples in which a taxon appears at least once. This code will produce a plot of all of the Phyla present in our samples along with information about their prevalence (fraction of samples they are present in) and total abundance across all samples. In this example we drew a dashed horizontal line to cross at the 5% prevalence level (present in \\\> 5% of all of the samples in the study).

```{r prevelance-filtering, eval=TRUE}
# Remove specific taxa
# Define a list with taxa to remove
filterPhyla = c( "Acidobacteria" )

get_taxa_unique(ps1, "Phylum")
ps1.prev <- subset_taxa(ps1, !Phylum %in% filterPhyla) 
get_taxa_unique(ps1.prev, "Phylum")

# Removing taxa that fall below 0.5% prevelance
# Define the prevalence threshold
prevalenceThreshold <- 0.005 * nsamples(ps1)
prevalenceThreshold

# Define which taxa fall within the prevalence threshold
keepTaxa <- rownames(prevdf1)[prevdf1$Prevalence >= floor(prevalenceThreshold)]


ntaxa(ps1)
# Remove those taxa
ps1.prev <- prune_taxa(keepTaxa, ps1)
ntaxa(ps1.prev)

# Save the new phyloseq object for downstream analysis
saveRDS(ps1, './RDS/ps1.RDS')
```

### 2. Data transformation - Rarefaction

Many analysis in community ecology and hypothesis testing benefit from data transformation. Many microbiome datasets do not fit to a normal distribution, but transforming them towards normality may enable more appropriate data for specific statistical tests. The choice of transformation is not straight forward. There is literature on how frequently used transformations affect certain analysis, but every data set may require different considerations. Therefore, it is recommended that you examine the effects of several transformations on your data and explore how they alter your results and interpretation. In this analysis, we will use rarefaction as our method of normalization.

```{r data-transform, eval=TRUE}
# Rarefy data
ps1 <- readRDS('./RDS/ps1.RDS')
ps1.rarefied <- rarefy_even_depth(ps1, rngseed=1, replace=F) #22OTUs were removed because they are no longer present in any sample after random subsampling

# Extract data from phyloseq object
seq_tab_rarefied <- otu_table(ps1.rarefied, taxa_are_rows = T)
taxatab_rarefied <- phyloseq::tax_table(ps1.rarefied)
sampleda <- sample_data(ps1.rarefied)

```

To visualize the refraction data, MicrobiotaProcess provides "ggrarecurve" to plot the curves, based on rarefy of vegan package.

```{r rarefaction curve, eval=TRUE}
# for reproducibly random number
set.seed(1024)

rareres <- get_rarecurve(obj=ps1.rarefied, chunks=400)

p_rare <- ggrarecurve(obj=rareres,
                      indexNames=c("Observe","Chao1", "ACE"),
                      ) +
          theme(legend.spacing.y=unit(0.01,"cm"),
                legend.text=element_text(size=4))

prare1 <- ggrarecurve(obj=rareres, factorNames="Group_name",
                      indexNames=c("Observe", "Chao1", "ACE")
                      ) +
          theme_bw() +
          theme(axis.text=element_text(size=8), panel.grid=element_blank(),
                strip.background = element_rect(colour=NA,fill="grey"),
                strip.text.x = element_text(face="bold"))   

prare2 <-  ggrarecurve(obj=rareres,
                      factorNames="Group_name",
                      shadow=FALSE,
                      indexNames=c("Observe", "Chao1", "ACE")
                      ) +
          scale_color_manual(values=c("#00AED7", "#FD9347"))+
          theme_bw()+
          theme(axis.text=element_text(size=8), panel.grid=element_blank(),
                strip.background = element_rect(colour=NA,fill="grey"),
                strip.text.x = element_text(face="bold"))

pdf("./01_Analysis/rarefaction_plots.pdf")

print(p_rare / prare1 / prare2)

# Finish recording and close the PDF file
dev.off()
```

### 3. Subset data into groups

In this section, we will subset the data into different groups. Particularly, we are interested in the samples from 'Colon Content' group in the main text, and other group in supplemental documents. So here, we subset our phyloseq object into three different group based on their 'Isolation.Source' in the metadata.

```{r subsetting, eval=TRUE}
#Subset rarefied data:

# Group 1: colon content
ps1.colon.rarefied <- subset_samples(ps1.rarefied, Isolation.Source=="colon_content")

# Group 2: Cecal content
ps1.cecal.rarefied <- subset_samples(ps1.rarefied, Isolation.Source=="ceacal_content")

```

We also want to transform the data into relative abundance

```{r transform to relative abundance, eval=TRUE}
#Subset rarefied data:

# Group 1: colon content
ps1.colon.rarefied.ra <- transform_sample_counts(ps1.colon.rarefied, function(ASV) ASV/sum(ASV) *100)

# Group 2: Cecal content
ps1.cecal.rarefied.ra <- transform_sample_counts(ps1.cecal.rarefied, function(ASV) ASV/sum(ASV) *100)
  
```

### 4. Alpha-diversity

Alpha-diversity represents diversity within an ecosystem or an sample. In other words, what is there and how much is there in terms of species. However, it is not easy to define a species, and we can calculate alpha-diversity at different taxonomic levels.

There are different indices we can calculate and interpret the alpha-diversity:

-   Richness represents the number of species observed in each sample (Observed).

-   Chao1 estimates the total richness.

-   Peilou's eveness provides information about the equity in species abundance in each sample. In other words, are some species dominating others or do all species have quite the same abundances.

-   Shannon index provides information about both richness and eveness.

> MicrobiotaProcess provides get_alphaindex to calculate alpha index. Six common diversity measures (Observe, Chao1, ACE, Shannon, Simpson, J) are supported. And the different groups of samples can be tested and visualize by ggbox.

To begin, we need to convert phyloseq object to mpse

```{r, eval=TRUE}
ps1.colon.rarefied.mpse <-  ps1.colon.rarefied %>% as.MPSE() # colon content
ps1.cecal.rarefied.mpse <- ps1.cecal.rarefied %>% as.MPSE() # cecal content
```

Then, calculate alpha-diversity indices

```{r, eval=TRUE}
# Calculate alpha diversity
alphaobj.colon_mpse1 <- ps1.colon.rarefied %>% as.MPSE() # colon content
alphaobj.colon_mpse1 %<>% mp_cal_alpha(.abundance=Abundance)

alphaobj.cecal_mpse1 <- ps1.cecal.rarefied %>% as.MPSE() # cecal content
alphaobj.cecal_mpse1 %<>% mp_cal_alpha(.abundance=Abundance)
```

Plot alpha diversity for each sample group

-   for colon content samples:

```{r, eval=TRUE}
p_alphaobj.colon <-  mp_plot_alpha(.data = alphaobj.colon_mpse1,
                                   .group= Treatment,
                                   .alpha = c(ACE, Chao1, Shannon), test = 'wilcox.test') +
                                   scale_fill_manual(values = alpha(c("steelblue","firebrick"), alpha=0.9), guide='none') + 
                                   scale_color_manual(values = alpha(c("steelblue", "firebrick"), alpha=0.9),  guide="none") +
                                   theme(strip.background = element_rect(colour=NA, fill="grey"),  axis.text.x = element_blank())  + theme(aspect.ratio=5/3) + labs(title = "Alpha Index of Samples from Colon Content")

p_alphaobj.colon

```

-   for cecal samples:

```{r, eval=TRUE}
p_alphaobj.cecal <-  mp_plot_alpha(.data = alphaobj.cecal_mpse1,
                                   .group= Treatment,
                                   .alpha = c(ACE, Chao1, Shannon), test = 'wilcox.test') + 
                                   scale_fill_manual(values = alpha(c("steelblue","firebrick"), alpha=0.9), guide='none') + 
                                   scale_color_manual(values = alpha(c("steelblue", "firebrick"), alpha=0.9),  guide="none") +
                                   theme(strip.background = element_rect(colour=NA, fill="grey"),  axis.text.x = element_blank()) +  theme(aspect.ratio=5/3) +
                                  labs(title = "Alpha Index of Samples from Cecal Content")

p_alphaobj.cecal
```

### 5. Beta-diversity

While alpha-diversity represents the diversity within an ecosystem or a sample, beta-diversity represents the difference between two ecosystems/samples. In other words, how similar or different are two ecosystems or samples? So, beta-diversity is a distance between two samples. We usually use Bray-Curtis or weight/unweight Unifrac distances to estimate the beta-diversity.

The Bray-Curtis disimilarity is based on occurunce data (abundance), while Jaccard distance is based on presence/absence data (does not include abundance information). UniFrac distances take into account the occurrence table and the phylogeny diversity (sequence distance). Weighted or unweighted UniFrac distances depending if taking into account relative abundance or only presence/absence. Distances metrics are between 0 and 1 (0 means identical communities in both samples and 1 means different communities in both samples).

The following R chunks calculate UniFrac and wUniFrac on a PhyloSeq object and display the the two components of these results that explain a majority of the variance in the data using Principle Coordinates Analysis (PCoA). For a detailed explanation of how PCoA works see: <https://sites.google.com/site/mb3gustame/dissimilarity-based-methods/principal-coordinates-analysis>.

```{r ordination, eval=TRUE}
#Ordination Analysis
ord.pcoa.wuni <- ordinate(ps1.rarefied, method = "PCoA", distance = 'wunifrac')
cecal.ord.pcoa.wuni <- ordinate(ps1.cecal.rarefied, method = "PCoA", distance = "wunifrac")
colon.ord.pcoa.wuni <- ordinate(ps1.colon.rarefied, method = "PCoA", distance = "wunifrac")
```

And now to plot each ordination

```{r, eval=TRUE}
# Weighted Unifrac
pdf("./Plots/PCoA.weighteduni_AllSamples.plots.pdf")
p.pcoa.wuni <- plot_ordination(ps1.rarefied, ord.pcoa.wuni, color = "Treatment", axes = c(1,2)) +
  geom_point(size = 2) + scale_color_manual(values = c("steelblue", "firebrick")) +
  geom_text(aes(label = NA), vjust = 1, size = 3) +  # Add point labels
  labs(title = "PCoA of wUniFrac Distances", color = "Treatment") + theme(aspect.ratio=3/5)
p.pcoa.wuni
dev.off()


########################################################################################
pdf("./Plots/PCoA.weighteduni_colon.plots.pdf")
p.pcoa.wuni <- plot_ordination(ps1.colon.rarefied, colon.ord.pcoa.wuni, color = "Treatment", axes = c(1,2)) +
  geom_point(size = 2) + scale_color_manual(values = c("steelblue", "firebrick")) +
  geom_text(aes(label = NA), vjust = 1, size = 3) +  # Add point labels
  labs(title = "PCoA of wUniFrac Distances", color = "Treatment") + theme(aspect.ratio=3/5)
p.pcoa.wuni
dev.off()


########################################################################################
# Weighted Unifrac
pdf("./Plots/PCoA.weighteduni_cecal.plots.pdf")
p.pcoa.wuni_cecal <- plot_ordination(ps1.cecal.rarefied, cecal.ord.pcoa.wuni, color = "Treatment", axes = c(1,2)) +
  geom_point(size = 2) + scale_color_manual(values = c("steelblue", "firebrick")) +
  geom_text(aes(label = NA), vjust = 1, size = 3) +  # Add point labels
  labs(title = "PCoA of wUniFrac Distances", color = "Treatment")  + theme(aspect.ratio=3/5)
p.pcoa.wuni_cecal
dev.off()
```

### 6. Group significance testing with ADONIS

We can use different statistical tests in odrer of test if there is any significant differences between treatments: parametric tests (t-test and ANOVA) or non-parametric test (Mann-Whitney and Kruskal-Wallis), before using parametric tests, we need to make sure that we can use the test (e.g. normal distribution, homoscedasticity).

To test whether the groups are significant with respect to centroid and dispersion, a PERMANOVA statistical test will be performed. For this, a multivariate extension of ANOVA will be used, as there are many ASVs that will be used in the test. The extension is based on distances between samples. The test compares distances of samples within the same group to distances of samples from different groups. If the distance between the samples from the different groups is much larger than samples from the same group, we conclude that the groups are not equal.

In order to test the significance of the result, a permutation test is used. Thus, all samples are randomly mixed over the groups and the test is repeated many times. If the ratio (between group distance / within group distance) is much larger for the original data than for the permutations, we conclude that there is a statistical significant difference.

The test can be applied in combination with any distance measure. Here we use the UniFrac distance as was also used for the PCoA above.

We will first test the effect of the treatment

```{r adonis-script, eval=TRUE}
# Set a random seed so that exact results can be reproduced
set.seed(10000)

# Function to run adonis test on a physeq object and a variable from metadata 
doadonis <- function(physeq, category) {
  bdist <- phyloseq::distance(physeq, "unifrac")
  col <- as(sample_data(physeq), "data.frame")[ ,category]
  
  # Adonis test
  adonis.bdist <- adonis(bdist ~ col)
  print("Adonis results:")
  print(adonis.bdist)
}

########################################################################################
# Apply the doadonis function to each dataset
permanova_all <- doadonis(ps1.rarefied, "Treatment")
print(permanova_all)
write.table(permanova_all$aov.tab, "./permanova_all.txt")

permanova_colon <- doadonis(ps1.colon.rarefied, "Treatment")
print(permanova_colon)
write.table(permanova_colon$aov.tab, "./permanova_colon.txt")

permanova_cecal <- doadonis(ps1.cecal.rarefied, "Treatment")
print(permanova_cecal)
write.table(permanova_cecal$aov.tab, "./permanova_cecal.txt")

```

The Total Sum of Squares is obtained from summing up all squared distances and dividing this by the number of samples - 1. The Residuals sum of squares (or within group sum of squares) is obtained by adding all squared distances of samples in the same group and divide this by the number of samples per group. The site sum of squares (or between group sum of squares) = SSTotal - SSResiduals. The F.model value then is obtained by the ratio of the Mean Squares (which are the Sum of squares divided by their degrees of freedom). The fraction of permuted results that provide a higher F value than the original data Pr(\>F) represents the p-value which is significant when \< 0.05.

Interpretation of the results for colon samples:

> "Df" "SumsOfSqs" "MeanSqs" "F.Model" "R2" "Pr(\>F)"
>
> "col" 1 0.209501588446528 0.209501588446528 1.63276404235345 0.21391517323127 0.027
>
> "Residuals" 6 0.769866005174472 0.128311000862412 NA 0.78608482676873 NA
>
> "Total" 7 0.979367593621 NA NA 1 NA
>
> The P-value is inferior to 0.05 for the effect of the treatment in colon samples. Thus, we can conclude that the intra-variability is lower than the inter-variability among the different treatments and that we have a significant effect of the treatments.

### 7. Bacterial community composition

#### Phylum level

We will visualize here the global bacterial composition in different sampling sites (Colon and Cecal) for each treatment. We already calculated the relative abundance for all samples, we will then sum all the ASVs that belong to the same Phylum and visualize the data.

```{r color pallet, eval=TRUE}
colors <- c('#F0C18A','#008D47','blue','#767BBB','#CCCC64','#00AEAA' , '#908E35', '#915323', '#FDD379', '#D1D1CC','#3D57A7', '#00ABD2', 
            '#F5EB00', '#A0489B','#F26822','#F175AD', '#919799', '#B52026', '#BCAED5', '#3E8386','#CCCC64' ,
            '#5793CE', '#8D3E1E', '#6591CC', '#986627', '#D75345', '#483987' , '#951B53', '#696A6C')

```

For colon samples

```{r, eval=TRUE}
# Create a data table for ggplot
ps1.colon.rarefied_phylum <- ps1.colon.rarefied  %>%
  tax_glom(taxrank = "Phylum") %>%                      # agglomerate at phylum level
  transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance (or use ps1.colon.rarefied.ra)
  psmelt()                                    # Melt to long format for easy ggploting

```

```{r plot colon, eval=TRUE}

# Plot - Phylum

p.ps1.colon.rarefied_phylum <- ggplot(ps1.colon.rarefied_phylum, aes(x = Sample_name, y = Abundance, fill = Phylum)) + 
  geom_bar(stat = "identity", width = 0.8, ) +
  facet_wrap(~Treatment, scales = "free_x", nrow = 4, ncol = 7) +
  theme(axis.text.x = element_blank()) +
  theme(axis.title.x = element_blank()) +
  labs(title = "Relative Abundant Phyla in All Colon Content") + 
  scale_fill_manual(values=colors) +
  theme(
    legend.key.size = unit(0.5, "cm"),   # Reduce the size of the legend key (box)
    legend.key.height = unit(0.5, "cm"), 
    legend.text = element_text(size = 10),   # Adjust the size of the legend text
    axis.line = element_line(size = 0.3),   # Set size of x and y axis lines
    panel.grid.major = element_blank(),     # Remove major grid lines
    panel.grid.minor = element_blank()     # Remove minor grid lines
  ) + theme(aspect.ratio=1/0.5)

pdf("./Plots/Colon_relative_plot_phylum.pdf")
print(p.ps1.colon.rarefied_phylum)
dev.off()
```

For cecal samples

```{r, eval=TRUE}
# Create a data table for ggplot
ps1.cecal.rarefied_phylum <- ps1.cecal.rarefied  %>%
  tax_glom(taxrank = "Phylum") %>%                      # agglomerate at phylum level
  transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance (or use ps1.cecal.rarefied.ra)
  psmelt()                                    # Melt to long format for easy ggploting

```

```{r plot cecal, eval=TRUE}

# Plot - Phylum

p.ps1.cecal.rarefied_phylum <- ggplot(ps1.cecal.rarefied_phylum, aes(x = Sample_name, y = Abundance, fill = Phylum)) + 
  geom_bar(stat = "identity", width = 0.8, ) +
  facet_wrap(~Treatment, scales = "free_x", nrow = 4, ncol = 7) +
  theme(axis.text.x = element_blank()) +
  theme(axis.title.x = element_blank()) +
  labs(title = "Relative Abundant Phyla in All Colon Content") + 
  scale_fill_manual(values=colors) +
  theme(
    legend.key.size = unit(0.5, "cm"),   # Reduce the size of the legend key (box)
    legend.key.height = unit(0.5, "cm"), 
    legend.text = element_text(size = 10),   # Adjust the size of the legend text
    axis.line = element_line(size = 0.3),   # Set size of x and y axis lines
    panel.grid.major = element_blank(),     # Remove major grid lines
    panel.grid.minor = element_blank()     # Remove minor grid lines
  ) + theme(aspect.ratio=1/0.5)


pdf("./Plots/Cecal_relative_plot_phylum.pdf")
print(p.ps1.cecal.rarefied_phylum)
dev.off()
```

In this study, we especially interested in specific groups of bacteria (Bacteroidetes , Firmicutes , Proteobacteria, Verrucomicrobia) that are affected by the treatment more than others, so we isolate these bacteria and calculate their ratio of relative abundance.

For colon samples

```{r, eval=TRUE}
# Filter data for Bacteroidetes , Firmicutes , Proteobacteria, Verrucomicrobia
bacteroidetes_data <- phylum_ps1.colon.rarefied %>%
  filter(Phylum == "Bacteroidetes")

firmicutes_data <- phylum_ps1.colon.rarefied %>%
  filter(Phylum == "Firmicutes")

proteobacteria_data <- phylum_ps1.colon.rarefied %>%
  filter(Phylum == "Proteobacteria")

verrucomicrobia_data <- phylum_ps1.colon.rarefied %>%
  filter(Phylum == "Verrucomicrobia")
```

```{r, eval=TRUE}
# Create a new data table containing ratio relative abundance between groups
# Sum abundance for each sample for each phylum
bacteroidetes_sum <- summarise(group_by(bacteroidetes_data, Sample, Treatment), Abundance = sum(Abundance))
firmicutes_sum <- summarise(group_by(firmicutes_data, Sample, Treatment), Abundance = sum(Abundance))
proteobacteria_sum <- summarise(group_by(proteobacteria_data, Sample, Treatment), Abundance = sum(Abundance))
verrucomicrobia_sum <- summarise(group_by(verrucomicrobia_data, Sample, Treatment), Abundance = sum(Abundance))

########################################################################################
# Merge the two data frames based on the Sample column
merged_data_bf <- merge(bacteroidetes_sum, firmicutes_sum, by = "Sample", suffixes = c("_Bacteroidetes", "_Firmicutes"))
merged_data_pf <- merge(proteobacteria_sum, firmicutes_sum, by = "Sample", suffixes = c("_Proteobacteria", "_Firmicutes"))
merged_data_vf <- merge(verrucomicrobia_sum, firmicutes_sum, by = "Sample", suffixes = c("_Verrucomicrobia", "_Firmicutes"))


########################################################################################
# Calculate the Bacteroidetes/Firmicutes ratio
merged_data_bf$Bact_Firm_Ratio <- merged_data_bf$Abundance_Bacteroidetes / merged_data_bf$Abundance_Firmicutes
write.table(merged_data_bf, "./Tables/merged_data_bf.tsv", sep='\t', row.names = FALSE) # save into a table

########################################################################################
# Calculate the Proteobacteria/Firmicutes ratio
merged_data_pf$Prot_Firm_Ratio <- merged_data_pf$Abundance_Proteobacteria / merged_data_pf$Abundance_Firmicutes
write.table(merged_data_pf, "./Tables/merged_data_pf.tsv", sep='\t', row.names = FALSE) # save into a table

########################################################################################
# Calculate the Verrucomicrobia/Firmicutes ratio
merged_data_vf$Verr_Firm_Ratio <- merged_data_vf$Abundance_Verrucomicrobia / merged_data_vf$Abundance_Firmicutes
write.table(merged_data_vf, "./Tables/merged_data_vf.tsv", sep='\t', row.names = FALSE) # save into a table
```

Perform Wilcoxon rank-sum to see whether these ratios are statistically significant between treatment and control groups, then we visualize results using boxplot with p-value.

```{r, eval=TRUE}
# Perform Wilcoxon rank-sum test
wilcox_test_result_bf <- wilcox.test(Bact_Firm_Ratio ~ Treatment_Firmicutes, data = merged_data_bf)

########################################################################################


# Create the ggplot
p_bf <- ggplot(merged_data_bf, aes(x = Treatment_Firmicutes, y = Bact_Firm_Ratio, fill = Treatment_Firmicutes)) +
  geom_boxplot() +
  labs(x = NULL, y = "Bacteroidetes/Firmicutes") +
  theme_minimal() + 
  scale_fill_manual(name = "Treatment", values = alpha(c("steelblue", "firebrick"), alpha=0.9)) +
  
  # Add p-value annotation
  annotate("text", x = 1.5, y = 0.65,
           label = sprintf("p = %.4f", wilcox_test_result_bf$p.value),
           hjust = 0.5, vjust = 0, size = 5)
pdf('./Plots/Colon.Bact_Firm_Ratio_phy.pdf')
p_bf
dev.off()

########################################################################################

# Create a boxplot Proteobacteria/Firmicutes 
wilcox_test_result_pf <- wilcox.test(merged_data_pf$Prot_Firm_Ratio ~ Treatment_Firmicutes, data = merged_data_pf)
p_pf <- ggplot(merged_data_pf, aes(x = Treatment_Firmicutes, y = Prot_Firm_Ratio, fill = Treatment_Firmicutes)) +
  geom_boxplot() +
  labs(x=NULL, y = "Proteobacteria/Firmicutes") +
  theme_minimal() + 
  scale_fill_manual(name = "Treatment", values = c("steelblue", "firebrick")) +
  
  # Add p-value annotation
  annotate("text", x = 1.5, y = 0.09,
           label = sprintf("p = %.4f", wilcox_test_result_pf$p.value),
           hjust = 0.5, vjust = 0, size = 5)
pdf('./Plots/Colon.Prot_Firm_Ratio_phy.pdf')
p_pf
dev.off()

########################################################################################


# Create a boxplot Verr_Firm
wilcox_test_result_vf <- wilcox.test(merged_data_vf$Verr_Firm_Ratio ~ Treatment_Firmicutes, data = merged_data_vf)
p_vf <- ggplot(merged_data_vf, aes(x = Treatment_Firmicutes, y = Verr_Firm_Ratio, fill = Treatment_Firmicutes)) +
  geom_boxplot() +
  labs(x=NULL, y = "Proteobacteria/Firmicutes") +
  theme_minimal() + 
  scale_fill_manual(name = "Treatment", values = c("steelblue", "firebrick")) +
  
  # Add p-value annotation
  annotate("text", x = 1.5, y = 0.5,
           label = sprintf("p = %.4f", wilcox_test_result_vf$p.value),
           hjust = 0.5, vjust = 0, size = 5)
pdf('./Plots/Colon.Verr_Firm_Ratio_phy.pdf')
p_vf
dev.off()
```

#### Genus level

For colon samples

```{r, eval=TRUE}
ps1.colon_genus<- ps1.colon.rarefied %>%
  tax_glom(taxrank = "Genus") %>%                      # agglomerate at phylum level
  transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance (or use ps1.colon.ra)
  psmelt() %>%                                         # Melt to long format for easy ggploting
  filter(Abundance > 0.005)                             # Filter out low abundance taxa


# Plot - Genus
p.ps1.colon_genus <- ggplot(ps1.colon_genus, aes(x = Sample_name, y = Abundance, fill = Genus)) + 
  geom_bar(stat = "identity", width = 0.8, ) +
  facet_wrap(~Treatment, scales = "free_x", nrow = 4, ncol = 7) +
  theme(axis.text.x = element_blank()) +
  theme(axis.title.x = element_blank()) +
  labs(title = "Realtive Abundant Genus in Colon Content") + 
  scale_fill_manual(values=colors) +
  theme(
    legend.key.size = unit(0.3, "cm"),   # Reduce the size of the legend key (box)
    legend.key.height = unit(0.3, "cm"), 
    legend.text = element_text(size = 10),   # Adjust the size of the legend text
    axis.line = element_line(size = 0.3),   # Set size of x and y axis lines
    panel.grid.major = element_blank(),     # Remove major grid lines
    panel.grid.minor = element_blank()     # Remove minor grid lines
  ) + theme(aspect.ratio=1/0.5)



# You can rerun the first bit of code in this chunk and change Phylum to Species, Genus, etc.


pdf("./Plots/Colon_relative_plot_genus.pdf")
print(p.ps1.colon_genus)
dev.off()
```

For cecal samples

```{r, eval=TRUE}
ps1.cecal_genus<- ps1.cecal.rarefied %>%
  tax_glom(taxrank = "Genus") %>%                      # agglomerate at phylum level
  transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance (or use ps1.cecal.ra)
  psmelt() %>%                                         # Melt to long format for easy ggploting
  filter(Abundance > 0.005)                             # Filter out low abundance taxa


# Plot - Genus
p.ps1.cecal_genus <- ggplot(ps1.cecal_genus, aes(x = Sample_name, y = Abundance, fill = Genus)) + 
  geom_bar(stat = "identity", width = 0.8, ) +
  facet_wrap(~Treatment, scales = "free_x", nrow = 4, ncol = 7) +
  theme(axis.text.x = element_blank()) +
  theme(axis.title.x = element_blank()) +
  labs(title = "Realtive Abundant Genus in Cecal Content") + 
  scale_fill_manual(values=colors) +
  theme(
    legend.key.size = unit(0.3, "cm"),   # Reduce the size of the legend key (box)
    legend.key.height = unit(0.3, "cm"), 
    legend.text = element_text(size = 10),   # Adjust the size of the legend text
    axis.line = element_line(size = 0.3),   # Set size of x and y axis lines
    panel.grid.major = element_blank(),     # Remove major grid lines
    panel.grid.minor = element_blank()     # Remove minor grid lines
  ) + theme(aspect.ratio=1/0.5)



# You can rerun the first bit of code in this chunk and change Phylum to Species, Genus, etc.


pdf("./Plots/Cecal_relative_plot_genus.pdf")
print(p.ps1.cecal_genus)
dev.off()
```

Calculate ratio at genus level

```{r, eval=TRUE}
ps1.colon.rarefied ## This is phyloseq of Colon content

# Filter data for Bacteroides , Roseburis , Escherichia, Roseburia, Parabacteroides 
colon_bacteroides_data <- ps1.colon.rarefied %>%
  filter(Genus == "Bacteroides")

colon_escherichia_data <- ps1.colon.rarefied %>%
  filter(Genus == "Escherichia/Shigella")

colon_roseburia_data <- ps1.colon.rarefied %>%
  filter(Genus == "Roseburia")

colon_parabacteroides_data <- ps1.colon.rarefied %>%
  filter(Genus == "Parabacteroides")
```

```{r, eval=TRUE}
# Sum abundance for each sample for each phylum
colon_bacteroides_sum <- summarise(group_by(colon_bacteroides_data, Sample, Treatment), Abundance = sum(Abundance))
colon_escherichia_sum <- summarise(group_by(colon_escherichia_data, Sample, Treatment), Abundance = sum(Abundance))
colon_roseburia_sum <- summarise(group_by(colon_roseburia_data, Sample, Treatment), Abundance = sum(Abundance))
colon_parabacteroides_sum <- summarise(group_by(colon_parabacteroides_data, Sample, Treatment), Abundance = sum(Abundance))


# Merge the two data frames based on the Sample column
colon_merged_data_Bacteroides_Roseburia <- merge(colon_bacteroides_sum, colon_roseburia_sum, by = "Sample", suffixes = c("_Bacteroides", "_Roseburia"))
colon_merged_data_Escherichia_Roseburia <- merge(colon_escherichia_sum, colon_roseburia_sum, by = "Sample", suffixes = c("_Escherichia", "_Roseburia"))
colon_merged_data_Parabacteroides_Bacteroides <- merge(colon_parabacteroides_sum, colon_bacteroides_sum, by = "Sample", suffixes = c("_Parabacteroides", "_Bacteroides"))


# Calculate the Bacteroides_Roseburia ratio
colon_merged_data_Bacteroides_Roseburia$Bact_Rose_Ratio <- colon_merged_data_Bacteroides_Roseburia$Abundance_Bacteroides/ colon_merged_data_Bacteroides_Roseburia$Abundance_Roseburia
#write.table(colon_merged_data_Bacteroides_Roseburia, "./Tables/colon_merged_data_Bacteroides_Roseburia.tsv", sep='\t', row.names = FALSE) # save into a table

# Calculate theEscherichia_Roseburia ratio
colon_merged_data_Escherichia_Roseburia$Escherichia_Roseburia_Ratio <- colon_merged_data_Escherichia_Roseburia$Abundance_Escherichia / colon_merged_data_Escherichia_Roseburia$Abundance_Roseburia
#write.table(colon_merged_data_Escherichia_Roseburia, "./Tables/colon_merged_data_Escherichia_Roseburia.tsv", sep='\t', row.names = FALSE) # save into a table

# Calculate the Parabacteroides_Bacteroides ratio
colon_merged_data_Parabacteroides_Bacteroides$Para_Bact_Ratio <- colon_merged_data_Parabacteroides_Bacteroides$Abundance_Parabacteroides / colon_merged_data_Parabacteroides_Bacteroides$Abundance_Bacteroides
#write.table(colon_merged_data_Parabacteroides_Bacteroides, "./Tables/colon_merged_data_Parabacteroides_Bacteroides.tsv", sep='\t', row.names = FALSE) # save into a table

```

### 8. Differential abundance analysis with ALDEx2

Use ALDEx2 to calculate statistical difference between our two groups, this is one way we can try to find out which ASVs (and possibly which taxa) are contributing to that difference

#### Colon samples

```{r, eval=TRUE}
# set seed to rule out different results from randomness
set.seed(1)

ps1.colon_genus

mm_aldex_genus_colon <- run_aldex(
     ps1.colon_genus,
     group = 'Treatment',
     taxa_rank = "Genus",
     method = "glm_anova", # Generalized linear model (GLM) approach for comparing means. Appropriate for non-normally distributed count data, especially when dealing with microbiome data.
     pvalue_cutoff = 0.05,
     mc_samples = 128 )

```

Plot cladogram

```{r, eval=TRUE}
pdf('./Plots/Colon_aldex_2_Genus_cladogram.pdf')
plot<- plot_cladogram(mm_aldex_genus_colon, color = c("steelblue", "firebrick"), alpha=0.5, branch_size = 0.5) 
dev.off()
```

Plot heatmap

```{r, eval=TRUE}
pdf('./plots/Colon)aldex_heatmap_genus.pdf')
plot_heatmap(mm_aldex_genus_colon, transform = "log10p", group = "Treatment",   cluster_marker = TRUE)
dev.off()

```

#### Cecal samples

```{r, eval=TRUE}
# set seed to rule out different results from randomness
set.seed(1)

ps1.cecal_genus

mm_aldex_genus_cecal <- run_aldex(
     ps1.colon_genus,
     group = 'Treatment',
     taxa_rank = "Genus",
     method = "glm_anova", # Generalized linear model (GLM) approach for comparing means. Appropriate for non-normally distributed count data, especially when dealing with microbiome data.
     pvalue_cutoff = 0.05,
     mc_samples = 128 )
```

Plot cladogram

```{r, eval=TRUE}
pdf('./Plots/Cecal_aldex_2_Genus_cladogram.pdf')
plot<- plot_cladogram(mm_aldex_genus_cecal, color = c("steelblue", "firebrick"), alpha=0.5, branch_size = 0.5) 
dev.off()
```

Plot heatmap

```{r, eval=TRUE}
pdf('./plots/Cecal_aldex_heatmap_genus.pdf')
plot_heatmap(mm_aldex_genus_cecal, transform = "log10p", group = "Treatment",   cluster_marker = TRUE)
dev.off()

```























